{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snorkel Linto üéßüìî"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sommaire \n",
    "#### 1. Chargement des donn√©es \n",
    "#### 2. D√©finition des labels \n",
    "#### 3. S√©paration train/test/dev\n",
    "#### 4. Ecriture des r√®gles\n",
    "#### 5. Application des r√®gles\n",
    "#### 6. Mod√®le g√©n√©ratif\n",
    "#### 7. Analyse r√©sultats\n",
    "#### 8. Cr√©ation fichiers utiles sur la sortie du mod√®le g√©n√©ratif \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Turn off TensorFlow logging messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "DISPLAY_ALL_TEXT = True\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0 if DISPLAY_ALL_TEXT else 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "\n",
    "# si pas d√©j√† charg√©: recup du mod√®le fran√ßais\n",
    "#! python -m spacy download fr_core_news_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe √† charger \n",
    "\n",
    "df_linto = pd.read_csv(\"../data/df_all_10022021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustements pour \"coller\" avec la tok√©nisation de spacy\n",
    "\n",
    "df_linto.loc[df_linto.word==\"aujourd'\", \"word\"]=\"aujourd\"\n",
    "df_linto.loc[df_linto.word==\"#0\", \"word\"]=\"0\"\n",
    "df_linto.loc[df_linto.word==\"95%\", \"word\"]=\"95\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>beg_word</th>\n",
       "      <th>end_word</th>\n",
       "      <th>n_round</th>\n",
       "      <th>beg_round</th>\n",
       "      <th>end_round</th>\n",
       "      <th>rank_round</th>\n",
       "      <th>text_round</th>\n",
       "      <th>sil_bef</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_point_bef</th>\n",
       "      <th>prob_comma_bef</th>\n",
       "      <th>real_rank_round</th>\n",
       "      <th>pitch</th>\n",
       "      <th>energy</th>\n",
       "      <th>pitch_bef</th>\n",
       "      <th>energy_bef</th>\n",
       "      <th>punct</th>\n",
       "      <th>punct_bef</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ok</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>0</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>donc</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>1</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>juste</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>2</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>comme</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>3</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.286862</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>on</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>4</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   word  beg_word  end_word  n_round  beg_round  end_round  \\\n",
       "0  0           ok     2.00      2.37      0        0.0        10.123      \n",
       "1  1           donc   2.73      3.01      0        0.0        10.123      \n",
       "2  2           juste  3.38      3.67      0        0.0        10.123      \n",
       "3  3           comme  3.92      4.22      0        0.0        10.123      \n",
       "4  4           on     4.23      4.67      0        0.0        10.123      \n",
       "\n",
       "   rank_round  \\\n",
       "0  0            \n",
       "1  1            \n",
       "2  2            \n",
       "3  3            \n",
       "4  4            \n",
       "\n",
       "                                                                     text_round  \\\n",
       "0  ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario   \n",
       "1  ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario   \n",
       "2  ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario   \n",
       "3  ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario   \n",
       "4  ok donc juste comme on enregistre euh donc l√† c' est le le deuxi√®me sc√©nario   \n",
       "\n",
       "   sil_bef  ...  prob_point_bef  prob_comma_bef  real_rank_round  pitch  \\\n",
       "0  1.26     ...  0.000000        0.000000        0                0       \n",
       "1  0.00     ...  0.000000        0.000000        1                0       \n",
       "2  0.24     ...  0.000000        0.000000        2                U       \n",
       "3  0.00     ...  0.018153        0.286862        3                D       \n",
       "4  0.00     ...  0.000417        0.001607        4                D       \n",
       "\n",
       "   energy  pitch_bef  energy_bef  punct  punct_bef         file  \n",
       "0  0       0          0           0      0          Linagora_P1  \n",
       "1  0       0          0           0      0          Linagora_P1  \n",
       "2  D       0          0           0      0          Linagora_P1  \n",
       "3  D       U          D           0      0          Linagora_P1  \n",
       "4  U       D          D           0      0          Linagora_P1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_linto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linagora_A1',\n",
       " 'Linagora_C1',\n",
       " 'Linagora_C2',\n",
       " 'Linagora_C3',\n",
       " 'Linagora_P1',\n",
       " 'Linagora_P4',\n",
       " 'Linagora_P5',\n",
       " 'Linagora_P6',\n",
       " 'Linagora_R1',\n",
       " 'Linagora_R3',\n",
       " 'Linagora_R4'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_linto[\"file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajout d'informations dans la Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 %\n",
      "50 %\n",
      "75 %\n"
     ]
    }
   ],
   "source": [
    "#token sur dev\n",
    "df_linto.index=np.arange(df_linto.shape[0])\n",
    "liste_token=[]\n",
    "i=0\n",
    "lim=25\n",
    "flag=0\n",
    "for x in df_linto.itertuples():\n",
    "    i+=1\n",
    "    per=(i*100)/len(df_linto)\n",
    "    if per>lim:\n",
    "        print(lim, \"%\")\n",
    "        lim=lim+25\n",
    "         \n",
    "    if flag==0:    \n",
    "        str_text=x.text_round\n",
    "        str_text=str_text.replace(\"  \", \" \")\n",
    "        str_text=str_text.replace(\"aujourd'\", \"aujourd\")\n",
    "        str_text=str_text.replace(\"95%\", \"95\")\n",
    "        str_text=str_text.replace(\"#0\", \"0\")\n",
    "        str_text=str_text.replace(\"' \", \"'\")\n",
    "        doc=nlp(str_text)\n",
    "       \n",
    "        if x.rank_round>=len(doc):\n",
    "            #print( x.text_round)\n",
    "            print(doc)\n",
    "            print(len(str(x.text_round).split(\" \")), len(doc))\n",
    "            #print((token.text_) for token in doc)\n",
    "        else:\n",
    "            liste_token.append(doc[int(x.rank_round)])\n",
    "\n",
    "    elif flag==1:\n",
    "        liste_token.append(doc[int(x.rank_round)])\n",
    "    \n",
    "    if x.rank_round<len(doc)-1:\n",
    "        flag=1\n",
    "    else:\n",
    "        flag=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_bef=[liste_token[0]]+liste_token\n",
    "del list_bef[-1]\n",
    "list_aft=liste_token+[liste_token[-1]]\n",
    "del list_aft[0]\n",
    "\n",
    "# information (pos type) sur le token du mot √©tudi√©, du pr√©c√©dent et du suivant  \n",
    "df_linto[\"token\"]=[token.pos_ for token in liste_token]\n",
    "df_linto[\"token_bef\"]=[token.pos_ for token in list_bef]\n",
    "df_linto[\"token_aft\"]=[token.pos_ for token in list_aft]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rajout de energy aft et pitch aft\n",
    "liste_energy=[]\n",
    "liste_pitch=[]\n",
    "liste_pos=[]\n",
    "for x in df_linto.itertuples():\n",
    "    liste_energy.append(x.energy)\n",
    "    liste_pitch.append(x.pitch)\n",
    "    \n",
    "df_linto[\"energy_aft\"]=liste_energy[1:]+[liste_energy[-1]]\n",
    "df_linto[\"pitch_aft\"]=liste_pitch[1:]+[liste_pitch[-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. D√©finition des labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "NO = 0\n",
    "BOS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. S√©paration train/test/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9752 8833 53692\n"
     ]
    }
   ],
   "source": [
    "df_dev = df_linto[(df_linto[\"file\"]==\"Linagora_R1\") | (df_linto[\"file\"]==\"Linagora_A1\")]\n",
    "df_test = df_linto[(df_linto[\"file\"]==\"Linagora_P1\") | (df_linto[\"file\"]==\"Linagora_C1\")]\n",
    "df_train=df_linto[(df_linto[\"file\"]!=\"Linagora_R1\")&(df_linto[\"file\"]!=\"Linagora_A1\")&(df_linto[\"file\"]!=\"Linagora_P1\")&(df_linto[\"file\"]!=\"Linagora_C1\")]\n",
    "\n",
    "\n",
    "Y_test = df_test[\"gold\"].values\n",
    "Y_dev = df_dev[\"gold\"].values\n",
    "\n",
    "print(len(df_dev),len(df_test),len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation des donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_obs=df_dev[(df_dev[\"gold\"]==1)]\n",
    "#a=df_obs['word'].dep_.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ecriture des r√®gles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√®gles basiques (sans preprocessor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "\n",
    "# Si tony dit BOS -> BOS\n",
    "@labeling_function()\n",
    "def tony(x):\n",
    "    return BOS if x[\"tony\"]==1 else ABSTAIN\n",
    "\n",
    "#  Si d√©but tour -> BOS \n",
    "@labeling_function()\n",
    "def beg_round(x):\n",
    "    return BOS if x[\"rank_round\"]==0 else ABSTAIN\n",
    "\n",
    "# Si la probabilit√© d'avoir un point juste avant est > 0.3 -> BOS \n",
    "@labeling_function()\n",
    "def point_bef(x):\n",
    "    return BOS if x[\"prob_point_bef\"]>0.3 and x[\"word\"]!=\"euh\" else ABSTAIN\n",
    "\n",
    "# Si probabilit√© de ne pas avoir de ponctuation > 0.99 -> NO\n",
    "@labeling_function()\n",
    "def nothing_bef(x):\n",
    "    return NO if x[\"prob_nothing_bef\"]>0.99 else ABSTAIN\n",
    "\n",
    "# Si probabilit√© d'avoir une virgule avant le mot >0.3 -> BOS\n",
    "@labeling_function()\n",
    "def comma_bef(x):\n",
    "     return BOS if x[\"prob_comma_bef\"]>0.3 else ABSTAIN\n",
    "\n",
    "\n",
    "# Si autour du mot il y a r√©p√©tition (hors \"euh\") -> NO\n",
    "@labeling_function()\n",
    "def no_disfluency(x):\n",
    "    param_context=4\n",
    "    list_text=str(x[\"text_round\"]).split(\" \")\n",
    "    pos=int(x[\"rank_round\"])\n",
    "    context=[]\n",
    "    cmpt=0\n",
    "    if pos>param_context and pos<len(list_text)-param_context:\n",
    "        for e in list_text[pos-param_context:pos+param_context]:\n",
    "            context.append(e)\n",
    "        while \"euh\" in context:\n",
    "            context.remove(\"euh\")\n",
    "            cmpt+=1\n",
    "        if abs(len(set(context))-len(context))>=2 or cmpt>2:\n",
    "            return NO\n",
    "        \n",
    "    param_context=2\n",
    "    context=[]\n",
    "    cmpt=0\n",
    "    if pos>param_context and pos<len(list_text)-param_context:\n",
    "        for e in list_text[pos-param_context:pos+param_context]:\n",
    "            context.append(e)\n",
    "        if len(set(context))!=len(context):\n",
    "            return NO\n",
    "    return ABSTAIN\n",
    "\n",
    "# Si l'√©nergie et le f0 suivent un motif particulier -> BOS\n",
    "@labeling_function()\n",
    "def energy_pitch(x):\n",
    "    liste_features=[\"DUUS\", \"DDUS\", \"DDUU\", \"SDUD\", \"SUUD\", \"SUUU\"]\n",
    "    str_feat=str(x.energy_bef)+str(x.energy)+str(x.pitch_bef)+str(x.pitch)\n",
    "    \n",
    "    if str_feat in liste_features and x.word!=\"euh\" and x.sil_bef>0.3:\n",
    "        return BOS\n",
    "\n",
    "    return ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def energy_pitch2(x):\n",
    "    if x.sil_bef>0.3:\n",
    "        if (x.energy_bef==\"D\" and x.pitch_bef==\"U\") and x.word!=\"euh\":\n",
    "            return BOS\n",
    "    return ABSTAIN\n",
    "\n",
    "# Si l'√©nergie et le f0 suivent un motif particulier -> NO\n",
    "@labeling_function()\n",
    "def no_energy_pitch(x):\n",
    "    list_nrj_bef=[\"S\", \"U\"]\n",
    "    list_pitch_bef=[\"D\", \"S\"]\n",
    "    beg_markers=[\"bonjour\", \"quand\", \"par\",\"merci\", \"ok\", \"bon\",\"ouais\",\"oui\",\"pour\", \"donc\",\"effectivement\",\"alors\",\"bref\",\"voil√†\", \"et\", \"ensuite\", \"mais\", \"ben\", \"hein\", \"enfin\", \"finalement\", \"pourtant\", \"cependant\", \"parce\"]\n",
    "    pronoms=[\"je\", \"tu\", \"il\", \"vous\", \"on\", \"nous\", \"elle\", \"ils\",\"qui\", \"que\", \"j'\",\"c'\"]\n",
    "    if (x.energy_bef in list_nrj_bef and x.pitch_bef in list_pitch_bef)or  (x.energy_bef==\"D\" and x.energy==\"D\"):\n",
    "        if x.word not in beg_markers and x.word not in pronoms:\n",
    "            return NO\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# Si le mot est d'un type particulier -> BOS \n",
    "@labeling_function()\n",
    "def cc(x):\n",
    "    notype=[\"ADJ\", \"DET\", \"AUX\", \"VERB\"]\n",
    "    if x.i_token in liste_begcc :#and x.token not in notype:\n",
    "        return BOS\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "\n",
    "liste_tok=[\"CCONJ\"]\n",
    "liste_tok_bef=[\"NOUN\"]\n",
    "liste_tok_dep=[\"nsubj\", \"cc\", \"advmod\", \"nmod\", \"amod\", \"expl:subj\", \"obj\", \"dep\"]\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def pos(x):\n",
    "    if x.token in liste_tok and x.token_bef!=\"CCONJ\" and x.token_aft!=\"NOUN\" and x.prob_comma_bef>0.05:\n",
    "        return BOS\n",
    "    return ABSTAIN\n",
    "\n",
    "# Si les mots avant, apr√®s et le mot ont des types particuliers -> BOS \n",
    "@labeling_function()\n",
    "def cconj(x):\n",
    "    liste_no=[\"euh\", \"pas\", \"que\", \"ou\", \"tu\", \"aussi\", \"l√†\"]\n",
    "    if (x.token_bef==\"NOUN\" and  x.token==\"CCONJ\" and x.token_aft==\"PRON\") or (x.token_bef==\"NOUN\" and  x.token==\"SCONJ\" and x.token_aft==\"SCONJ\") or (x.token_bef==\"NOUN\" and  x.token==\"ADV\" and x.token_aft==\"PRON\") and x.word not in liste_no:\n",
    "        return BOS\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "# Si le mod√®le de samir met un point avant le mot -> BOS\n",
    "@labeling_function()\n",
    "def punct_samir_period(x):\n",
    "    if x.punct_bef==\".\" and x.word!=\"euh\" and x.sil_bef>0:\n",
    "        return BOS\n",
    "    return ABSTAIN \n",
    "\n",
    "# Si le mod√®le de samir met une virgule avant le mot -> BOS\n",
    "@labeling_function()\n",
    "def punct_samir_comma(x):\n",
    "    if x.punct_bef==\",\" and x.word!=\"euh\" and x.sil_bef>0:\n",
    "        return BOS\n",
    "    return ABSTAIN \n",
    "\n",
    "# Si le mot d'avant est un NOUN et l'√©nergie avant est descendante (D) -> BOS\n",
    "@labeling_function()\n",
    "def noun_d(x):\n",
    "    liste_tok=[\"PRON\", \"ADV\", \"CCONJ\"]\n",
    "    if x.token_bef==\"NOUN\" and x.energy_bef==\"D\" and x.token in liste_tok and x.energy!=\"D\":\n",
    "        return BOS\n",
    "    return ABSTAIN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√®gles avec pre-processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "# The SpacyPreprocessor parses the text in text_field and\n",
    "# stores the new enriched representation in doc_field\n",
    "spacy = SpacyPreprocessor(text_field=\"word\",language='fr_core_news_sm', doc_field=\"doc\", memoize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from snorkel.preprocess import preprocessor\n",
    "\n",
    "# rajoute le contexte √† droite et √† gauche du mot\n",
    "@preprocessor(memoize=True)\n",
    "def word_context(x):\n",
    "    list_text=str(x[\"text_round\"]).split(\" \")\n",
    "    pos=int(x[\"rank_round\"])\n",
    "    if pos<len(list_text)-1 and pos>0:\n",
    "        x.word_bef = list_text[pos-1]\n",
    "        x.word_aft = list_text[pos+1]\n",
    "    elif pos==0 and pos<len(list_text)-1:\n",
    "        x.word_bef = np.nan\n",
    "        x.word_aft= list_text[pos+1]\n",
    "    elif pos==len(list_text)-1 and pos==0:\n",
    "        x.word_aft = np.nan\n",
    "        x.word_bef = list_text[pos-1]\n",
    "    else:\n",
    "        x.word_aft = np.nan\n",
    "        x.word_bef = np.nan\n",
    "    return x\n",
    "\n",
    "\n",
    "#preprocessor qui indique les marqueurs qui comptent vraiment (le premier si on a une suite de marqueurs)\n",
    "@preprocessor(memoize=True)\n",
    "def markers(x):\n",
    "    #definir marqueurs seuls\n",
    "    couples_markers=dict(du=[\"coup\"], de=[\"fait\"], en=[\"fait\", \"vrai\", \"effet\"], parce=[\"que\",\"qu'\"], et=[\"puis\", \"donc\"],enfin=[\"bon\"],mais=[\"bon\"], √†=[\"propos\"], tu=[\"vois\",\"sais\"])\n",
    "    single_markers=[\"ouais\", \"donc\",\"effectivement\",\"alors\",\"bref\",\"voil√†\", \"ensuite\", \"mais\", \"ben\", \"hein\", \"enfin\", \"finalement\", \"pourtant\", \"cependant\"]\n",
    "    \n",
    "    list_text=str(x[\"text_round\"]).split(\" \")\n",
    "    wrd=str(x[\"word\"])\n",
    "    pos=int(x[\"rank_round\"])\n",
    "    \n",
    "    m=0\n",
    "    if pos!=len(list_text)-1:\n",
    "        wrd_aft=str(list_text[pos+1])\n",
    "        if wrd in single_markers or ((wrd in couples_markers.keys()) and (wrd_aft in couples_markers[wrd])):\n",
    "            if pos==0:\n",
    "                m=1\n",
    "            else:\n",
    "                wrd_bef=str(list_text[pos-1])\n",
    "                if wrd_bef in single_markers:\n",
    "                    m=0\n",
    "                else:\n",
    "                    if pos==1:\n",
    "                        m=1\n",
    "                    else:\n",
    "                        wrd_bef_bef=str(list_text[pos-2])\n",
    "                        if wrd_bef_bef in couples_markers.keys() and wrd_bef in couples_markers[wrd_bef_bef]:\n",
    "                            m=0\n",
    "                        else:\n",
    "                            m=1\n",
    "    x.marker=m\n",
    "    return x\n",
    "\n",
    "# indique si le mot est √† la suite d'un marqueur ou d'une serie de marqueurs\n",
    "@preprocessor(memoize=True)\n",
    "def aft_markers(x):\n",
    "    couples_markers=dict(du=[\"coup\"], de=[\"fait\"], en=[\"fait\", \"vrai\", \"effet\"], parce=[\"que\",\"qu'\"], et=[\"puis\", \"donc\"],enfin=[\"bon\"],mais=[\"bon\"], √†=[\"propos\"], tu=[\"vois\",\"sais\"])\n",
    "    single_markers=[\"ouais\", \"donc\",\"effectivement\",\"alors\",\"bref\",\"voil√†\", \"et\", \"ensuite\", \"mais\", \"ben\", \"hein\", \"enfin\", \"finalement\", \"pourtant\", \"cependant\"]\n",
    "    \n",
    "    list_text=str(x[\"text_round\"]).split(\" \")\n",
    "    wrd=str(x[\"word\"])\n",
    "    pos=int(x[\"rank_round\"])\n",
    "    bef=0\n",
    "    aft_mark=0\n",
    "    if pos>0:\n",
    "        wrd_bef=str(list_text[pos-1])\n",
    "        for k in couples_markers.keys():\n",
    "            if wrd_bef in couples_markers[k]:\n",
    "                bef=1\n",
    "        #print(wrd, wrd_bef, bef)\n",
    "        if wrd_bef in single_markers or bef==1:\n",
    "            if wrd not in single_markers and wrd not in couples_markers.keys():\n",
    "                aft_mark=1\n",
    "            else:\n",
    "                aft_mark=0\n",
    "        else:\n",
    "            aft_mark=0\n",
    "    \n",
    "    x.aft_mark=aft_mark\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processor \"markers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si premier marqueur d'une s√©rie ou marqueur isol√©e -> BOS\n",
    "@labeling_function(pre=[markers])\n",
    "def first_marker(x):\n",
    "    if x.marker==1:\n",
    "        return BOS\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processor \"aft_markers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si mot √† la suite d'un marqueur isol√© ou d'une s√©rie de marqueur -> NO\n",
    "@labeling_function(pre=[aft_markers])\n",
    "def no_after_markers(x):\n",
    "    if x.aft_mark==1:\n",
    "        return NO\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processor \"spacy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si type particulier du mot -> NO\n",
    "@labeling_function(pre=[spacy])\n",
    "def no_type(x):\n",
    "    \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
    "    if  any([(token.pos_ == \"ADJ\" or token.pos_ == \"DET\" or token.pos_ == \"AUX\" or token.pos_ == \"VERB\") for token in x.doc]) :\n",
    "        return NO\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processor \"word_context\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If silence longer than 0.7s before the word -> BOS\n",
    "\n",
    "@labeling_function(pre=[word_context])\n",
    "def sil_bef(x):\n",
    "    \n",
    "    if x[\"sil_bef\"]>=0.7 and x.word_bef!=\"euh\" and x.word_aft!=\"euh\" and x.word_bef!=x.word_aft and x.word_bef!=x[\"word\"] and x.word_aft!=x[\"word\"] and x[\"word\"]!=\"euh\":\n",
    "        single_markers=[\"donc\",\"effectivement\",\"alors\",\"bref\",\"voil√†\", \"et\", \"ensuite\", \"mais\", \"ben\", \"hein\", \"enfin\", \"finalement\", \"pourtant\", \"cependant\"]\n",
    "        pronoms=[\"je\", \"tu\", \"il\", \"vous\", \"on\", \"nous\", \"elle\", \"ils\"]\n",
    "        #if x.word_bef not in single_markers and x.word_bef not in pronoms:\n",
    "        return BOS\n",
    "\n",
    "\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "\n",
    "# If no silence before the word -> NO\n",
    "@labeling_function(pre=[word_context])\n",
    "def no_sil_bef(x):\n",
    "    beg_markers=[\"bon\",\"ouais\",\"oui\",\"pour\", \"donc\",\"effectivement\",\"alors\",\"bref\",\"voil√†\", \"et\", \"ensuite\", \"mais\", \"ben\", \"hein\", \"enfin\", \"finalement\", \"pourtant\", \"cependant\", \"parce\"]\n",
    "    pronoms=[\"je\", \"tu\", \"il\", \"vous\", \"on\", \"nous\", \"elle\", \"ils\",\"qui\", \"que\", \"j'\",\"c'\"]\n",
    "    if x[\"sil_bef\"]==0 and x[\"word\"]==\"en\" and x.word_aft==\"fait\":\n",
    "            return ABSTAIN\n",
    "    elif x[\"sil_bef\"]==0 and x[\"word\"] not in beg_markers and x[\"word\"] not in pronoms:\n",
    "        return NO\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Si mot particulier -> BOS\n",
    "@labeling_function(pre=[word_context])\n",
    "def keywords(x):\n",
    "    liste=[\"bonjour\", \"merci\", \"ok\", \"oui\", \"non\", \"ouais\"]\n",
    "    beg_markers=[\"bon\",\"ouais\",\"oui\",\"pour\", \"donc\",\"effectivement\",\"alors\",\"bref\",\"voil√†\", \"et\", \"ensuite\", \"mais\", \"ben\", \"hein\", \"enfin\", \"finalement\", \"pourtant\", \"cependant\", \"parce\"]\n",
    "    \n",
    "    \n",
    "    if x.word_bef not in liste and x.word_bef not in beg_markers:\n",
    "        if x.word in liste or (x.word==\"d'\" and x.word_aft==\"accord\") or (x.word==\"hum\" and x.word_aft==\"hum\"):\n",
    "            return BOS \n",
    "    return ABSTAIN\n",
    "\n",
    "# Si type de mot dans le contexte et √©nergie + pitch suivent un sch√©ma particulier -> BOS \n",
    "@labeling_function(pre=[word_context])\n",
    "def audio_spacy(x):\n",
    "    \n",
    "    beg_markers=[\"bon\",\"ouais\",\"oui\",\"pour\", \"donc\",\"effectivement\",\"alors\",\"bref\",\"voil√†\", \"et\", \"ensuite\", \"mais\", \"ben\", \"hein\", \"enfin\", \"finalement\", \"pourtant\", \"cependant\", \"parce\"]\n",
    "    \n",
    "    dict_e3=dict(NOUN_PRON_AUX=[\"DSS\", \"DUU\", \"DSU\"], NOUN_PRON_PRON=[\"DUS\", \"DDU\"], NOUN_CCONJ_ADV=[\"DDD\"], NOUN_ADV_PRON=[\"DDU\", \"DDD\", \"DDS\"],\n",
    "            NOUN_CCONJ_PRON=[\"DUD\"])\n",
    "    \n",
    "    dict_ep2=dict(NOUN_PRON=[\"DKDS\", \"USDU\", \"UDDU\", \"DKDU\"],NOUN_ADV=[\"SSDD\", \"UDDD\", \"USDD\"], NOUN_CCONJ=[\"UDDU\", \"SKDU\"] )\n",
    "    \n",
    "    dict_e2=dict(NOUN_PRON=[\"DS\"], NOUN_CCONJ=[\"DD\", \"DU\", \"SU\"], ADJ_PRON=[\"US\"], NOUN_SCONJ=[\"DD\"], PROPN_PRON=[\"DU\", \"DS\", \"UD\"], ADV_CCONJ=[\"DD\", \"DU\"])\n",
    "    \n",
    "    tok3=x.token_bef+\"_\"+x.token+\"_\"+x.token_aft\n",
    "    tok2=x.token_bef+\"_\"+x.token\n",
    "    e3=str(x.energy_bef)+str(x.energy)+str(x.energy_aft)\n",
    "    e2=str(x.energy_bef)+str(x.energy)\n",
    "    ep=str(x.pitch_bef)+str(x.pitch)+str(x.energy_bef)+str(x.energy)\n",
    "    if x.word_bef not in beg_markers:\n",
    "        if tok3 in dict_e3.keys() and e3 in dict_e3[tok3]:\n",
    "            return BOS\n",
    "        if tok2 in dict_ep2.keys() and ep in dict_ep2[tok2]:\n",
    "            return BOS\n",
    "\n",
    "        if tok2 in dict_e2.keys() and e2 in dict_e2[tok2]:\n",
    "            return BOS\n",
    "    return ABSTAIN\n",
    "\n",
    "# Tony am√©lior√© \n",
    "# If ToNy detects a Segment -> Begin of Segment (BOS)\n",
    "@labeling_function(pre=[word_context])\n",
    "def tony(x):\n",
    "    beg_markers=[\"bon\",\"ouais\",\"oui\",\"pour\", \"donc\",\"effectivement\",\"alors\",\"bref\",\"voil√†\", \"et\", \"ensuite\", \"mais\", \"ben\", \"hein\", \"enfin\", \"finalement\", \"pourtant\", \"cependant\", \"parce\"]\n",
    "    if x[\"tony\"]==1:\n",
    "        if x.word_bef not in beg_markers:\n",
    "            if (x.word==\"on\" and x.sil_bef==0) or (x.word==\"c'\" and x.token_bef==\"VERB\"):\n",
    "                return ABSTAIN\n",
    "            else: \n",
    "                return BOS \n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G√©n√©ration de r√®gles avec des KeyWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non utilis√© mais peut √™tre utilis√©\n",
    "from snorkel.labeling import LabelingFunction\n",
    "\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(wrd in x.word.lower() for wrd in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(keywords, label=BOS):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"Spam comments make requests rather than commenting.\"\"\"\n",
    "keyword_words = make_keyword_lf(keywords=[\"bonjour\",\"merci\",\"ok\"],label=BOS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R√®gle sur les vrais tours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si d√©but de vrai tour -> BOS\n",
    "@labeling_function()\n",
    "def beg_real_round(x):\n",
    "    if x.real_rank_round==0:\n",
    "        return BOS\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Application des r√®gles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/linto/lgravell/.conda/envs/linto/lib/python3.8/site-packages/tqdm/std.py:699: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9752/9752 [00:56<00:00, 172.39it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8833/8833 [00:50<00:00, 175.11it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53692/53692 [05:14<00:00, 170.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs=[ cconj, tony, first_marker,  no_type, no_sil_bef, no_after_markers, no_disfluency, point_bef, nothing_bef, keywords, audio_spacy, no_energy_pitch]\n",
    "#lfs=[cconj, tony, first_marker, no_sil_bef, no_after_markers, no_disfluency, point_bef, nothing_bef, keywords, pos,cc, energy_pitch, no_energy_pitch, energy_pitch2]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_dev = applier.apply(df=df_dev)\n",
    "L_test = applier.apply(df=df_test)\n",
    "L_train = applier.apply(df=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation de la couverture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelingFunction cconj, Preprocessors: [] coverage: 0.9%\n",
      "LabelingFunction tony, Preprocessors: [LambdaMapper word_context, Pre: []] coverage: 9.8%\n",
      "LabelingFunction first_marker, Preprocessors: [LambdaMapper markers, Pre: []] coverage: 4.5%\n",
      "LabelingFunction no_type, Preprocessors: [SpacyPreprocessor SpacyPreprocessor, Pre: []] coverage: 34.5%\n",
      "LabelingFunction no_sil_bef, Preprocessors: [LambdaMapper word_context, Pre: []] coverage: 64.3%\n",
      "LabelingFunction no_after_markers, Preprocessors: [LambdaMapper aft_markers, Pre: []] coverage: 7.9%\n",
      "LabelingFunction no_disfluency, Preprocessors: [] coverage: 17.5%\n",
      "LabelingFunction point_bef, Preprocessors: [] coverage: 6.7%\n",
      "LabelingFunction nothing_bef, Preprocessors: [] coverage: 49.6%\n",
      "LabelingFunction keywords, Preprocessors: [LambdaMapper word_context, Pre: []] coverage: 1.7%\n",
      "LabelingFunction audio_spacy, Preprocessors: [LambdaMapper word_context, Pre: []] coverage: 2.4%\n",
      "LabelingFunction no_energy_pitch, Preprocessors: [] coverage: 37.8%\n"
     ]
    }
   ],
   "source": [
    "coverage = (L_train != ABSTAIN).mean(axis=0)\n",
    "i=0\n",
    "for score in list(coverage):\n",
    "    print(lfs[i], f\"coverage: {score * 100:.1f}%\")\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation du L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cconj</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.009424</td>\n",
       "      <td>0.009126</td>\n",
       "      <td>0.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tony</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.097892</td>\n",
       "      <td>0.075467</td>\n",
       "      <td>0.039186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_marker</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.044588</td>\n",
       "      <td>0.038814</td>\n",
       "      <td>0.017004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_type</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.344744</td>\n",
       "      <td>0.336680</td>\n",
       "      <td>0.022145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_sil_bef</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.643150</td>\n",
       "      <td>0.593515</td>\n",
       "      <td>0.030172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_after_markers</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.063268</td>\n",
       "      <td>0.004973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_disfluency</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.175147</td>\n",
       "      <td>0.156243</td>\n",
       "      <td>0.022815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_bef</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.066565</td>\n",
       "      <td>0.058482</td>\n",
       "      <td>0.028757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothing_bef</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.495772</td>\n",
       "      <td>0.468785</td>\n",
       "      <td>0.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keywords</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>0.010132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_spacy</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.023821</td>\n",
       "      <td>0.021251</td>\n",
       "      <td>0.008195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_energy_pitch</th>\n",
       "      <td>11</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.377971</td>\n",
       "      <td>0.364803</td>\n",
       "      <td>0.028105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "cconj             0   [1]      0.009424  0.009126  0.002105 \n",
       "tony              1   [1]      0.097892  0.075467  0.039186 \n",
       "first_marker      2   [1]      0.044588  0.038814  0.017004 \n",
       "no_type           3   [0]      0.344744  0.336680  0.022145 \n",
       "no_sil_bef        4   [0]      0.643150  0.593515  0.030172 \n",
       "no_after_markers  5   [0]      0.079248  0.063268  0.004973 \n",
       "no_disfluency     6   [0]      0.175147  0.156243  0.022815 \n",
       "point_bef         7   [1]      0.066565  0.058482  0.028757 \n",
       "nothing_bef       8   [0]      0.495772  0.468785  0.008400 \n",
       "keywords          9   [1]      0.017191  0.015701  0.010132 \n",
       "audio_spacy       10  [1]      0.023821  0.021251  0.008195 \n",
       "no_energy_pitch   11  [0]      0.377971  0.364803  0.028105 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train summary \n",
    "from snorkel.labeling import LFAnalysis\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   j Polarity  Coverage  Overlaps  Conflicts\n",
      "cconj             0   [1]      0.009424  0.009126  0.002105 \n",
      "tony              1   [1]      0.097892  0.075467  0.039186 \n",
      "first_marker      2   [1]      0.044588  0.038814  0.017004 \n",
      "no_type           3   [0]      0.344744  0.336680  0.022145 \n",
      "no_sil_bef        4   [0]      0.643150  0.593515  0.030172 \n",
      "no_after_markers  5   [0]      0.079248  0.063268  0.004973 \n",
      "no_disfluency     6   [0]      0.175147  0.156243  0.022815 \n",
      "point_bef         7   [1]      0.066565  0.058482  0.028757 \n",
      "nothing_bef       8   [0]      0.495772  0.468785  0.008400 \n",
      "keywords          9   [1]      0.017191  0.015701  0.010132 \n",
      "audio_spacy       10  [1]      0.023821  0.021251  0.008195 \n",
      "no_energy_pitch   11  [0]      0.377971  0.364803  0.028105 \n"
     ]
    }
   ],
   "source": [
    "print(LFAnalysis(L=L_train, lfs=lfs).lf_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des r√®gles sur le set de d√©veloppement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cconj</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tony</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.094852</td>\n",
       "      <td>0.075574</td>\n",
       "      <td>0.036608</td>\n",
       "      <td>615</td>\n",
       "      <td>310</td>\n",
       "      <td>0.664865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_marker</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.051169</td>\n",
       "      <td>0.043786</td>\n",
       "      <td>0.019073</td>\n",
       "      <td>338</td>\n",
       "      <td>161</td>\n",
       "      <td>0.677355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_type</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.331317</td>\n",
       "      <td>0.321678</td>\n",
       "      <td>0.020509</td>\n",
       "      <td>3108</td>\n",
       "      <td>123</td>\n",
       "      <td>0.961931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_sil_bef</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.602851</td>\n",
       "      <td>0.557527</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>5742</td>\n",
       "      <td>137</td>\n",
       "      <td>0.976697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_after_markers</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.088905</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>822</td>\n",
       "      <td>45</td>\n",
       "      <td>0.948097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_disfluency</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.235747</td>\n",
       "      <td>0.210316</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>2121</td>\n",
       "      <td>178</td>\n",
       "      <td>0.922575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_bef</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.064705</td>\n",
       "      <td>0.058450</td>\n",
       "      <td>0.026354</td>\n",
       "      <td>449</td>\n",
       "      <td>182</td>\n",
       "      <td>0.711569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothing_bef</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.475185</td>\n",
       "      <td>0.449344</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>4618</td>\n",
       "      <td>16</td>\n",
       "      <td>0.996547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keywords</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.015279</td>\n",
       "      <td>0.013638</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>105</td>\n",
       "      <td>44</td>\n",
       "      <td>0.704698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio_spacy</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.028199</td>\n",
       "      <td>0.025021</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>202</td>\n",
       "      <td>73</td>\n",
       "      <td>0.734545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_energy_pitch</th>\n",
       "      <td>11</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.419606</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>3950</td>\n",
       "      <td>142</td>\n",
       "      <td>0.965298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "cconj             0   [1]      0.008203  0.008101  0.001743   71        \n",
       "tony              1   [1]      0.094852  0.075574  0.036608   615       \n",
       "first_marker      2   [1]      0.051169  0.043786  0.019073   338       \n",
       "no_type           3   [0]      0.331317  0.321678  0.020509   3108      \n",
       "no_sil_bef        4   [0]      0.602851  0.557527  0.021739   5742      \n",
       "no_after_markers  5   [0]      0.088905  0.071473  0.005435   822       \n",
       "no_disfluency     6   [0]      0.235747  0.210316  0.027584   2121      \n",
       "point_bef         7   [1]      0.064705  0.058450  0.026354   449       \n",
       "nothing_bef       8   [0]      0.475185  0.449344  0.008203   4618      \n",
       "keywords          9   [1]      0.015279  0.013638  0.008306   105       \n",
       "audio_spacy       10  [1]      0.028199  0.025021  0.008409   202       \n",
       "no_energy_pitch   11  [0]      0.419606  0.400533  0.023482   3950      \n",
       "\n",
       "                  Incorrect  Emp. Acc.  \n",
       "cconj             9          0.887500   \n",
       "tony              310        0.664865   \n",
       "first_marker      161        0.677355   \n",
       "no_type           123        0.961931   \n",
       "no_sil_bef        137        0.976697   \n",
       "no_after_markers  45         0.948097   \n",
       "no_disfluency     178        0.922575   \n",
       "point_bef         182        0.711569   \n",
       "nothing_bef       16         0.996547   \n",
       "keywords          44         0.704698   \n",
       "audio_spacy       73         0.734545   \n",
       "no_energy_pitch   142        0.965298   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev summary \n",
    "from snorkel.labeling import LFAnalysis\n",
    "a=LFAnalysis(L=L_dev, lfs=lfs).lf_summary(Y_dev)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cconj', 'tony', 'first_marker', 'no_type', 'no_sil_bef',\n",
      "       'no_after_markers', 'no_disfluency', 'point_bef', 'nothing_bef',\n",
      "       'keywords', 'audio_spacy', 'no_energy_pitch'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(a[\"Polarity\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores des r√®gles BOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cconj</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.062281</td>\n",
       "      <td>0.116393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tony</td>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.595642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first_marker</td>\n",
       "      <td>0.677355</td>\n",
       "      <td>0.296491</td>\n",
       "      <td>0.412447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>point_bef</td>\n",
       "      <td>0.711569</td>\n",
       "      <td>0.393860</td>\n",
       "      <td>0.507058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>keywords</td>\n",
       "      <td>0.704698</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.162917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audio_spacy</td>\n",
       "      <td>0.734545</td>\n",
       "      <td>0.177193</td>\n",
       "      <td>0.285512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rule  precision    recall    fscore\n",
       "0  cconj         0.887500   0.062281  0.116393\n",
       "1  tony          0.664865   0.539474  0.595642\n",
       "2  first_marker  0.677355   0.296491  0.412447\n",
       "3  point_bef     0.711569   0.393860  0.507058\n",
       "4  keywords      0.704698   0.092105  0.162917\n",
       "5  audio_spacy   0.734545   0.177193  0.285512"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1=Y_dev.sum() # nombre de cas positif \n",
    "s0=len(Y_dev)-s1 \n",
    "\n",
    "rule=[]\n",
    "p=[]\n",
    "r=[]\n",
    "fscore=[]\n",
    "rule=[]\n",
    "\n",
    "for x in a.itertuples():\n",
    "    if x.Polarity==[1]:\n",
    "        # precision = TP / (TP + FP ) \n",
    "        precision=int(x.Correct)/(int(x.Correct)+int(x.Incorrect))\n",
    "        p.append(precision)\n",
    "        # recall = TP /(TP + FN )\n",
    "        recall=(x.Correct)/(int(x.Correct)+(int(s1-x.Correct)))\n",
    "        r.append(recall)\n",
    "        # fscore= 2.(p.r / (p+r))\n",
    "        fscore.append(2*precision*recall/(precision+recall))\n",
    "        rule.append(x.Index)\n",
    "\n",
    "df_scores=pd.DataFrame({'rule': rule, 'precision': p, 'recall': r, 'fscore': fscore})\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mod√®le g√©n√©ratif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cr√©ation mod√®le g√©n√©ratif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_dev = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train,Y_dev=Y_dev, n_epochs=7000, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   88.9%\n",
      "Label Model Accuracy:     90.4%\n"
     ]
    }
   ],
   "source": [
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation de la sortie du mod√®le g√©n√©ratif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label model f1 score: 0.6708975521305531\n",
      "Label model precision score: 0.6941838649155723\n",
      "Label model recall score: 0.6491228070175439\n",
      "Label model roc-auc: 0.9162156436143772\n"
     ]
    }
   ],
   "source": [
    "# dev \n",
    "from snorkel.analysis import metric_score\n",
    "from snorkel.utils import probs_to_preds\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "print(\n",
    "    f\"Label model f1 score: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='f1')}\",\n",
    "    f\"Label model precision score: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='precision')}\",\n",
    "    f\"Label model recall score: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='recall')}\",\n",
    "    f\"Label model roc-auc: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='roc_auc')}\",\n",
    "    sep = \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Segeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary Similarity =  0.5293501048218029350104821803\n",
      "Boundary Similarity tony alone =  0.4678423236514522821576763485\n",
      "Segmentation Similarity =  0.9309372436423297785069729286\n",
      "entropie crois√©e =  0.023424403759274796\n"
     ]
    }
   ],
   "source": [
    "import segeval as se\n",
    "\n",
    "label=[]\n",
    "for e in probs_dev:\n",
    "    if e[1]>e[0] and e[1]>0.5:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "tony_list=[]       \n",
    "for x in df_dev.itertuples():\n",
    "    tony_list.append(x.tony)\n",
    "\n",
    "#print(len(Y_dev), len(label))\n",
    "gold_nltk=\"\"\n",
    "result_nltk=\"\"\n",
    "tony_nltk=\"\"\n",
    "\n",
    "\n",
    "for i in range(0,len(Y_dev)):\n",
    "    gold_nltk+=str(Y_dev[i])\n",
    "    result_nltk+=str(label[i])\n",
    "    tony_nltk+=str(tony_list[i])\n",
    "\n",
    "#print(len(gold_str), len(result_str))\n",
    "gold_masses=se.convert_nltk_to_masses(gold_nltk, boundary_symbol='1')\n",
    "result_masses=se.convert_nltk_to_masses(result_nltk, boundary_symbol='1')\n",
    "tony_masses=se.convert_nltk_to_masses(tony_nltk, boundary_symbol='1')\n",
    "nt=2\n",
    "print(\"Boundary Similarity = \", se.boundary_similarity(gold_masses, result_masses, n_t=nt))\n",
    "print(\"Boundary Similarity tony alone = \", se.boundary_similarity(gold_masses, tony_masses, n_t=nt))\n",
    "\n",
    "gold_str=se.boundary_string_from_masses(gold_masses)\n",
    "result_str=se.boundary_string_from_masses(result_masses)\n",
    "\n",
    "edit_distance=se.boundary_edit_distance(gold_str, result_str,3)\n",
    "#convert_masses_to_positions(masses)\n",
    "gold_positions=se.convert_masses_to_positions(gold_masses)\n",
    "result_positions=se.convert_masses_to_positions(result_masses)\n",
    "\n",
    "\n",
    "print(\"Segmentation Similarity = \",se.segmentation_similarity(gold_masses, result_masses))\n",
    "\n",
    "\n",
    "# Entropie crois√©e \n",
    "from math import *\n",
    "\n",
    "ec=0\n",
    "for i in range(0, len(probs_dev)):\n",
    "    ec+=log(probs_dev[i][1])*label[i]\n",
    "    \n",
    "ec=-ec/len(probs_dev)\n",
    "\n",
    "print(\"entropie crois√©e = \", ec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Label model f1 score: 0.6708975521305531\n",
      "Label model precision score: 0.6941838649155723\n",
      "Label model recall score: 0.6491228070175439\n",
      "Label model roc-auc: 0.9162156436143772\n"
     ]
    }
   ],
   "source": [
    "#calcul seuil\n",
    "print(type(preds_dev))\n",
    "\n",
    "label=[]\n",
    "for e in probs_dev:\n",
    "    if  e[1]>0.5:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "preds_dev=np.array(label)\n",
    "print(\n",
    "    f\"Label model f1 score: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='f1')}\",\n",
    "    f\"Label model precision score: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='precision')}\",\n",
    "    f\"Label model recall score: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='recall')}\",\n",
    "    f\"Label model roc-auc: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='roc_auc')}\",\n",
    "    sep = \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyse des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.around(label_model.get_weights(), 2) \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_probabilities_histogram(Y):\n",
    "    plt.hist(Y, bins=10)\n",
    "    plt.xlabel(\"Probability of BOS\")\n",
    "    plt.ylabel(\"Number of data points\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "plot_probabilities_histogram(probs_train[:, BOS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93, 0.63, 0.75, 1.  , 1.  , 0.72, 0.87, 0.72, 1.  , 0.7 , 0.77,\n",
       "       1.  ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(label_model.get_weights(), 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_label_frequency(L):\n",
    "    plt.hist((L != ABSTAIN).sum(axis=1), density=True, bins=range(L.shape[1]))\n",
    "    plt.xlabel(\"Number of labels\")\n",
    "    plt.ylabel(\"Fraction of dataset\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_label_frequency(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude des erreurs dans la sortie du mod√®le g√©n√©ratif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euh      33\n",
      "ouais    23\n",
      "bon      17\n",
      "√ßa       16\n",
      "c'       16\n",
      "hum      13\n",
      "en       12\n",
      "voil√†    11\n",
      "on       11\n",
      "que      10\n",
      "ce       10\n",
      "je       9 \n",
      "si       9 \n",
      "il       8 \n",
      "d'       7 \n",
      "ok       7 \n",
      "est      7 \n",
      "et       7 \n",
      "le       7 \n",
      "pour     6 \n",
      "Name: word, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Etude des erreurs apr√®s le mod√®le g√©n√©ratif\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "\n",
    "label=[]\n",
    "for e in probs_dev:\n",
    "    if e[1]>e[0] and e[1]>0.5:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "\n",
    "#cr√©ation fichier \n",
    "word2=df_dev[\"word\"].values\n",
    "\n",
    "df_analysis=pd.DataFrame({\"word\" : word2, \"label\": label, \"gold\" : Y_dev})\n",
    "df_analysis.head()\n",
    "\n",
    "\n",
    "df_obs2=df_analysis[(df_analysis[\"label\"]==0) & (df_analysis[\"gold\"]==1)]\n",
    "a=df_obs2['word'].value_counts()\n",
    "print(a[:20])\n",
    "\n",
    "\n",
    "#df_analysis.to_csv(\"analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cr√©ation de fichiers utiles sur la sortie du mod√®le g√©n√©ratif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Fichier pour entrainement/fine-tuning de ToNy\n",
    "<br>\n",
    "2.Fichier de visualisation des BOS de sortie du mod√®le g√©n√©ratif , comparaison avec le GOLD\n",
    "<br>\n",
    "3.Fichier de visualisation des virgules et leur lien avec les BOS\n",
    "<br>\n",
    "4.Fichier de visualisation des vrais tours VS tours d√©tect√©s automatiquement \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Fichier pour entrainement/fine-tuning de ToNy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_train = label_model.predict_proba(L_train)\n",
    "\n",
    "label=[]\n",
    "for e in probs_train:\n",
    "    if e[1]>e[0] and e[1]>0.5:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "\n",
    "#cr√©ation fichier \n",
    "\n",
    "file_tony=open(\"file_train_tony_18022021_V2beground.txt\", \"w\")\n",
    "i=0\n",
    "\n",
    "for x in df_train.itertuples():\n",
    "    if x.rank_round==0:\n",
    "        file_tony.write(\"\\n\")\n",
    "    if label[i]==1:\n",
    "        file_tony.write(str(x.word)+\"\\t\"+\"NN\"+\"\\t\"+\"O\"+\"\\t\"+\"B-S\"+\"\\n\")\n",
    "    else:\n",
    "        file_tony.write(str(x.word)+\"\\t\"+\"NN\"+\"\\t\"+\"O\"+\"\\t\"+\"O\"+\"\\n\")\n",
    "    i+=1\n",
    "file_tony.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr√©ation fichier \n",
    "\n",
    "file_tony=open(\"file_gold_dev_tony.txt\", \"w\")\n",
    "i=0\n",
    "\n",
    "for x in df_dev.itertuples():\n",
    "    if x.rank_round==0:\n",
    "        file_tony.write(\"\\n\")\n",
    "    if Y_dev[i]==1:\n",
    "        file_tony.write(str(x.word)+\"\\t\"+\"NN\"+\"\\t\"+\"O\"+\"\\t\"+\"B-S\"+\"\\n\")\n",
    "    else:\n",
    "        file_tony.write(str(x.word)+\"\\t\"+\"NN\"+\"\\t\"+\"O\"+\"\\t\"+\"O\"+\"\\n\")\n",
    "    i+=1\n",
    "\n",
    "file_tony.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Fichier de visualisation des BOS de sortie du mod√®le g√©n√©ratif , comparaison avec le GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cr√©ation d'un fichier de sortie joli pour v√©rifier qualitativement si √ßa marche bien \n",
    "\n",
    "\n",
    "label=[]\n",
    "for e in probs_dev:\n",
    "    if e[1]>e[0] and e[1]>0.5:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "\n",
    "#cr√©ation fichier \n",
    "\n",
    "file=open(\"readable_bos_output_generative_model.txt\", \"w\")\n",
    "\n",
    "\n",
    "i=0\n",
    "liste_texte=[]\n",
    "\n",
    "for x in df_dev.itertuples():\n",
    "    mot=x.word\n",
    "    if x.real_rank_round==0 :\n",
    "        if x.prob_point_bef<0.5 and i>0 and x.prob_comma_bef<0.5:\n",
    "            liste_texte.append(\".\")\n",
    "        liste_texte.append(\"\\n\"+\"\\n\"+\"---Spk---\"+\"\\n\"+\"\\n\")\n",
    "\n",
    "    if label[i]==1:\n",
    "        liste_texte.append(\"|D|\")\n",
    "    if Y_dev[i]==1:\n",
    "        liste_texte.append(\"|G|\")      \n",
    "    \n",
    "    \n",
    "    if x.prob_point_bef>0.5 or x.real_rank_round==0:\n",
    "        mot=str(mot).capitalize()\n",
    "    \n",
    "    if x.prob_point>0.5:\n",
    "        mot=mot+\".\"\n",
    "\n",
    "    if x.prob_comma>0.5:\n",
    "        mot=mot+\",\"\n",
    "\n",
    "    liste_texte.append(mot)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    i+=1\n",
    "    if i==len(df_dev):\n",
    "        liste_texte.append(\".\")\n",
    "\n",
    "file.write(\" \".join(liste_texte))\n",
    "\n",
    "file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Fichier de visualisation des virgules et leur lien avec les BOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation des virgules \n",
    "\n",
    "label=[]\n",
    "for e in probs_dev:\n",
    "    if e[1]>e[0] and e[1]>0.5:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "\n",
    "#cr√©ation fichier \n",
    "\n",
    "file=open(\"virgules_bos_19012021.txt\", \"w\")\n",
    "\n",
    "\n",
    "i=0\n",
    "liste_texte=[]\n",
    "\n",
    "for x in df_dev.itertuples():\n",
    "    mot=x.word\n",
    "    if x.real_rank_round==0 :\n",
    "        if x.prob_point_bef<0.5 and i>0 and x.prob_comma_bef<0.3:\n",
    "            liste_texte.append(\".\")\n",
    "        liste_texte.append(\"\\n\"+\"\\n\"+\"---Spk---\"+\"\\n\"+\"\\n\")\n",
    "\n",
    "    if Y_dev[i]==1:\n",
    "        liste_texte.append(\"|G|\")      \n",
    "    \n",
    "    \n",
    "    if x.prob_point_bef>0.5 or x.real_rank_round==0:\n",
    "        mot=str(mot).capitalize()\n",
    "    \n",
    "    if x.prob_point>0.5:\n",
    "        mot=mot+\".\"\n",
    "\n",
    "    if x.prob_comma>0.3:\n",
    "        mot=mot+\",\"\n",
    "\n",
    "    liste_texte.append(mot)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    i+=1\n",
    "    if i==len(df_dev):\n",
    "        liste_texte.append(\".\")\n",
    "\n",
    "file.write(\" \".join(liste_texte))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fichier de visualisation des vrais tours VS tours d√©tect√©s automatiquement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation erreur d echangmenet de speaker \n",
    "\n",
    "\n",
    "label=[]\n",
    "for e in probs_dev:\n",
    "    if e[1]>e[0] and e[1]>0.5:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "\n",
    "#cr√©ation fichier \n",
    "\n",
    "file=open(\"spk_change.txt\", \"w\")\n",
    "\n",
    "\n",
    "i=0\n",
    "liste_texte=[]\n",
    "\n",
    "for x in df_dev.itertuples():\n",
    "    mot=x.word\n",
    "    if x.rank_round==0 :\n",
    "        if x.prob_point_bef<0.5 and i>0 and x.prob_comma_bef<0.5:\n",
    "            liste_texte.append(\".\")\n",
    "        liste_texte.append(\"\\n\"+\"\\n\"+\"---Spk detected---\"+\"\\n\"+\"\\n\")\n",
    "\n",
    "    if x.real_rank_round==0:\n",
    "        liste_texte.append(\"|SPK|\")\n",
    "     \n",
    "   \n",
    "    if x.prob_point_bef>0.5 or x.real_rank_round==0:\n",
    "        mot=str(mot).capitalize()\n",
    "    \n",
    "    if x.prob_point>0.5:\n",
    "        mot=mot+\".\"\n",
    "\n",
    "    if x.prob_comma>0.5:\n",
    "        mot=mot+\",\"\n",
    "\n",
    "    liste_texte.append(mot)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    i+=1\n",
    "    if i==len(df_dev):\n",
    "        liste_texte.append(\".\")\n",
    "\n",
    "file.write(\" \".join(liste_texte))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonjou\n"
     ]
    }
   ],
   "source": [
    "# visualisation erreur d echangmenet de speaker \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file=open(\"spk_change_comparison_R1.txt\", \"w\")\n",
    "\n",
    "\n",
    "i=0\n",
    "liste_texte=[]\n",
    "\n",
    "for x in df_dev.itertuples():\n",
    "    mot=x.word\n",
    "    if x.real_rank_round==0 :\n",
    "        if x.prob_point_bef<0.5 and i>0 and x.prob_comma_bef<0.5:\n",
    "            liste_texte.append(\".\")\n",
    "        liste_texte.append(\"\\n\"+\"\\n\"+\"---Real turn---\"+\"\\n\"+\"\\n\")\n",
    "        \n",
    "\n",
    "    if x.rank_round==0:\n",
    "        liste_texte.append(\"|D_SPK|\")\n",
    "    \n",
    "    #if label[i]==1:\n",
    "        #liste_texte.append(\"|D_BOS|\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    if x.prob_point_bef>0.5 or x.real_rank_round==0:\n",
    "        mot=str(mot).capitalize()\n",
    "    \n",
    "    if x.prob_point>0.5:\n",
    "        mot=mot+\".\"\n",
    "\n",
    "    if x.prob_comma>0.5:\n",
    "        mot=mot+\",\"\n",
    "\n",
    "    liste_texte.append(mot)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    i+=1\n",
    "    if i==len(df_dev):\n",
    "        liste_texte.append(\".\")\n",
    "\n",
    "file.write(\" \".join(liste_texte))\n",
    "print(\"bonjou\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cr√©ation de fichier pour la d√©mo Gautier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53692 53692\n"
     ]
    }
   ],
   "source": [
    "# RAP 4\n",
    "probs_train = label_model.predict_proba(L_train)\n",
    "label=[]\n",
    "for e in probs_train:\n",
    "    if e[1]>e[0] and e[1]>0.5:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)\n",
    "\n",
    "\n",
    "df_train_bos=df_train.copy()\n",
    "\n",
    "print(len(df_train_bos), len(label))    \n",
    "    \n",
    "df_train_bos[\"bos_snorkel\"]=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.74\n"
     ]
    }
   ],
   "source": [
    "#df_train_bos[\"bos_snorkel\"]=label\n",
    "\n",
    "df_train_bos.head()\n",
    "\n",
    "file=open(\"rap4_actes_dialogues.txt\",\"w\")\n",
    "\n",
    "df_r4=df_train_bos[(df_train_bos[\"file\"]==\"Linagora_R4\")]\n",
    "\n",
    "df_r4.head()\n",
    "i=0\n",
    "deb=float(df_r4.iat[0,2])\n",
    "print(deb)\n",
    "text=[]\n",
    "for x in df_r4.itertuples():\n",
    "    if x.bos_snorkel==1 and i!=0:\n",
    "        \n",
    "        file.write(\"\\n\"+\"Linagora_R4 \"+str(deb)+\" \"+str(x.beg_word)+\" \"+\" \".join(text))\n",
    "        deb=x.beg_word\n",
    "        text=[]\n",
    "        \n",
    "    text.append(x.word)\n",
    "    i+=1\n",
    "        \n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"real_truns_timestamp\")\n",
    "\n",
    "for x in df_dev.itertuples():\n",
    "    if x.real_rank_round==0:\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linto",
   "language": "python",
   "name": "linto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
