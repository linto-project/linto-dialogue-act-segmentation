{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Création de la dataframe pour les actes de dialogues dans Snorkel\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,\"scripts/\")\n",
    "from alignments import *\n",
    "from tony import *\n",
    "from gold import *\n",
    "from silences import *\n",
    "from speaker import *\n",
    "from tony import *\n",
    "from gold import *\n",
    "from punctuation import *\n",
    "from pitchenergy import *\n",
    "from punctuation_samir import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emplacement des fichiers : \n",
    "\n",
    "name_meeting=\"Linagora_R1\"\n",
    "file_alignments=\"data/alignments/Linagora_R1_align.txt\"\n",
    "file_spk_change=\"data/speakers/Linagora_R1_spk.txt\"\n",
    "file_silences=\"data/silences/Linagora_R1_sil.txt\"\n",
    "file_tony_result=\"data/tony/Linagora_R1_tony.txt.split.tok\"\n",
    "file_gold=\"data/gold/Linagora_R1_gold.txt\"\n",
    "file_punct=\"data/punctuation/Linagora_R1_punct.txt\"\n",
    "file_punct_samir=\"data/punctuation_samir/Linagora_R1_samir.txt\"\n",
    "file_pitchenergy=\"data/audio/Linagora_R1_pitchenergy.txt\"\n",
    "\n",
    "    \n",
    "work_directory=\"path\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les fichiers nécessaires \n",
    "<br>\n",
    "\n",
    "#### 1. Fichiers d'alignements\n",
    "<br>\n",
    "Dans la réalité il suffira d'obtenir le résultat de la reconnaissance vocale, qui doit normalement fournir le mot transcrit, le début du mot en secondes et la fin du mot en secondes.\n",
    "Pour l'étude, il s'agit de la sortie du logiciel Jtrans en y mettant en entrée l'audio et le fichier .trs correspondant contenant la transcription faite par Authôt.\n",
    "<br>\n",
    "\n",
    "\n",
    "#### 2. Fichiers de détection de changement de locuteur \n",
    "<br>\n",
    "Il s'agit des fichiers de sortie de \"pyannote_SCD_OVL.ipynb\" qui prend en entrée un fichier wav et donne en sortie un fichier avec des segments en format hh:mm:ss de même locuteur. Il faut convertir ce fichier en segement en secondes.\n",
    "<br>\n",
    "\n",
    "#### 3. Fichier des segments de silence\n",
    "\n",
    "Fichiers issus de l'utilisation de Py WebRTCVad, qui ressemble à ça: <br>\n",
    "<br>\n",
    "*File : Linagora_A1_0_05_27--end.wav<br>\n",
    "0.09 0.30 0.18 NS<br>\n",
    "0.48 0.63 0.12 NS<br>\n",
    "...*<br>\n",
    "<br>\n",
    "Les trois premières colonnes correspondent à :\n",
    "Debut/Fin/Durée-3s/NS\n",
    "<br>\n",
    "#### 4. Fichier sortie de ToNy  \n",
    "<br>\n",
    "Fichiers issus de l'utilisation du système ToNy. Des fonctions ont été conçues pour créer les fichiers nécessaires à son utilisation. <br>\n",
    "Les fichiers de sortie de ToNy ressemblent à ça :<br>\n",
    "<br>\n",
    "*1\teh\t_\t_\t_\t_\t_\t_\t_\tBeginSeg=Yes<br>\n",
    "2\tben\t_\t_\t_\t_\t_\t_\t_\t_<br>\n",
    "3\tdu\t_\t_\t_\t_\t_\t_\t_\t_<br>\n",
    "4\tcoup\t_\t_\t_\t_\t_\t_\t_\t_<br>\n",
    "5\touais\t_\t_\t_\t_\t_\t_\t_\t_*<br>\n",
    "\n",
    "\n",
    "#### 5. Les fichiers Gold \n",
    "<br>\n",
    "Pour les réunions qui ont des labels GOLD, donner les fichiers textes avec les séparateurs | d'actes de dialogues\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liste des fonctions \n",
    "<br>\n",
    "\n",
    "### Alignements\n",
    "\n",
    "\n",
    "**alignments_word_extraction(filename_alignments)**\n",
    "> return **word, beg_word, end_word** \n",
    "> respectivement la liste des mots, le début des mots en secondes, la fin des mots en secondes \n",
    "<br>\n",
    "\n",
    "**alignments_real_round_extraction(filename_alignments)**\n",
    "> return n_round, beg_round, end_round, rank_round, text_round, loc\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### Détection changement de locuteurs\n",
    "\n",
    "<br>\n",
    "\n",
    "**read_change_spk_detection(filename_change_spk_detection)**\n",
    "> return **beg_chg_spk**, **end_chg_spk**\n",
    "\n",
    "\n",
    "**round_extraction(word, beg_word, end_word, beg_chg_spk ,end_chg_spk)**\n",
    "> return **n_round**, **beg_round**, **end_round**, **rank_round**, **text_round**\n",
    "\n",
    "<br>\n",
    "\n",
    "### Silences\n",
    "\n",
    "<br>\n",
    "\n",
    "**extract_silences_positions(filename_silences)**\n",
    "> return **beg_sil**, **end_sil**, **dur_sil**, **mid_sil**\n",
    "\n",
    "\n",
    "**silences_word_position(word, beg_word, end_word, beg_sil, end_sil, dur_sil, mid_sil)**\n",
    "> return **sil_bef**, **sil_aft**\n",
    "\n",
    "<br>\n",
    "\n",
    "### ToNy \n",
    "\n",
    "<br>\n",
    "\n",
    "**data_prep_tony(name, word, rank_round, text_round)**\n",
    "> create file for ToNy\n",
    "\n",
    "\n",
    "**convert_tony_results(filename_tony_result)**\n",
    "> return **tony**\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### Gold\n",
    "\n",
    "<br>\n",
    "\n",
    "**convert_gold(filename_gold)**\n",
    "> return **gold**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Ponctuation\n",
    "\n",
    "<br>\n",
    "\n",
    "**convert_punctuation(filename_punct)**\n",
    "> return **prob_nothing**, **prob_point**, **prob_comma**, **prob_nothing_bef**, **prob_point_bef**, **prob_comma_bef**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**punctuation_samir_extraction(file_punctuation, word)**\n",
    "> return **punct**, **punct_bef**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation pour une seule réunion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943 7943 7943\n"
     ]
    }
   ],
   "source": [
    "word,beg_word,end_word = alignments_word_extraction(file_alignments)\n",
    "print(len(word), len(beg_word), len(end_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943 7943 7943 7943 7943\n"
     ]
    }
   ],
   "source": [
    "real_n_round, real_beg_round, real_end_round, real_rank_round, real_text_round, real_loc=alignments_real_round_extraction(file_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Silences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943 7943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "beg_sil,end_sil,dur_sil,mid_sil=extract_silences_positions(file_silences)\n",
    "sil_bef, sil_aft=silences_word_position(word, beg_word, end_word, beg_sil, end_sil, dur_sil, mid_sil)\n",
    "\n",
    "print(len(sil_bef), len(sil_aft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Speaker change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 119\n",
      "7943 7943 7943 7943 7943 119 119\n"
     ]
    }
   ],
   "source": [
    "beg_chg_spk, end_chg_spk = read_change_spk(file_spk_change)\n",
    "print(len(beg_chg_spk), len(end_chg_spk))\n",
    "n_round, beg_round, end_round, rank_round, text_round = round_extraction(word, beg_word, end_word, beg_chg_spk, end_chg_spk)\n",
    "\n",
    "print(len(n_round), len(beg_round), len(end_round), len(rank_round), len(text_round), len(beg_chg_spk), len(end_chg_spk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ToNy Begin Of Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_prep_tony(name_meeting, word, rank_round, text_round)\n",
    "tony=convert_tony_results(file_tony_result, word)\n",
    "\n",
    "print(len(tony))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gold BOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943\n"
     ]
    }
   ],
   "source": [
    "if file_gold!=\"\":\n",
    "    gold=convert_gold(file_gold)\n",
    "    print(len(gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "7943\n",
      "7943 7943\n"
     ]
    }
   ],
   "source": [
    "prob_nothing, prob_point, prob_comma, prob_nothing_bef, prob_point_bef, prob_comma_bef = convert_punctuation(file_punct, word)\n",
    "print(len(prob_nothing))\n",
    "\n",
    "\n",
    "#ponctuation samir\n",
    "\n",
    "punct_bef, punct=punctuation_samir_extraction(file_punct_samir, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "7943 7943 7943 7943\n"
     ]
    }
   ],
   "source": [
    "pitch, pitch_bef, energy, energy_bef = audio_features_extraction(file_pitchenergy, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 137 67 7697\n",
      "precision= 0.3853211009174312 rappel= 0.2346368715083799 fscore= 0.2916666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vp=0\n",
    "fn=0\n",
    "fp=0\n",
    "vn=0\n",
    "\n",
    "\n",
    "for i in range(0,len(rank_round)):\n",
    "    if rank_round[i]==0 and real_rank_round[i]==0:\n",
    "        vp+=1\n",
    "    elif rank_round[i]!=0 and real_rank_round[i]==0:\n",
    "        fn+=1\n",
    "    elif rank_round[i]==0 and real_rank_round[i]!=0:\n",
    "        fp+=1\n",
    "    else:\n",
    "        vn+=1\n",
    "\n",
    "print(vp, fn, fp, vn)\n",
    "p=vp/(vp+fp)\n",
    "r=vp/(vp+fn)\n",
    "fscore=2*p*r/(p+r)\n",
    "\n",
    "print(\"precision=\", p, \"rappel=\", r, \"fscore=\", fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_dev = pd.DataFrame({'word': word, 'beg_word': beg_word, 'end_word': end_word,'n_round': n_round,\n",
    "                       'beg_round': beg_round, 'end_round': end_round, 'rank_round' : rank_round,\n",
    "                       'text_round' : text_round, 'sil_bef' : sil_bef, 'sil_aft' : sil_aft, 'tony' : tony,\n",
    "                       'gold': gold, 'prob_nothing' : prob_nothing, 'prob_point': prob_point,\n",
    "                       'prob_comma' : prob_comma, 'prob_nothing_bef' : prob_nothing_bef,\n",
    "                       'prob_point_bef': prob_point_bef, 'prob_comma_bef' : prob_comma_bef,\n",
    "                       'real_rank_round': real_rank_round, 'pitch': pitch, 'energy': energy,\n",
    "                       'pitch_bef': pitch_bef, 'energy_bef': energy_bef})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonjou\n"
     ]
    }
   ],
   "source": [
    "#df_dev=\n",
    "file=open(\"spk_change_comparison_R1.txt\", \"w\")\n",
    "\n",
    "\n",
    "i=0\n",
    "liste_texte=[]\n",
    "\n",
    "for x in df_dev.itertuples():\n",
    "    mot=x.word\n",
    "    if x.real_rank_round==0 :\n",
    "        if float(x.prob_point_bef)<0.5 and i>0 and float(x.prob_comma_bef)<0.5:\n",
    "            liste_texte.append(\".\")\n",
    "        liste_texte.append(\"\\n\"+\"\\n\"+\"---Real turn---\"+\"\\n\"+\"\\n\")\n",
    "        \n",
    "\n",
    "    if x.rank_round==0:\n",
    "        liste_texte.append(\"|D_SPK|\")\n",
    "    \n",
    "    #if label[i]==1:\n",
    "        #liste_texte.append(\"|D_BOS|\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    if float(x.prob_point_bef)>0.5 or x.real_rank_round==0:\n",
    "        mot=str(mot).capitalize()\n",
    "    \n",
    "    if float(x.prob_point)>0.5:\n",
    "        mot=mot+\".\"\n",
    "\n",
    "    if float(x.prob_comma)>0.5:\n",
    "        mot=mot+\",\"\n",
    "\n",
    "    liste_texte.append(mot)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    i+=1\n",
    "    if i==len(df_dev):\n",
    "        liste_texte.append(\".\")\n",
    "\n",
    "file.write(\" \".join(liste_texte))\n",
    "print(\"bonjou\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"real_rounds.txt\", \"w\")\n",
    "\n",
    "for i in range(0,len(real_rank_round)):\n",
    "    if real_rank_round[i]==0:\n",
    "        file.write(str(round(real_beg_round[i],3))+\" \"+str(round(real_end_round[i],3))+\" \"+real_loc[i]+\"\\n\")\n",
    "\n",
    "file.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de la dataframe globale avec toutes les réunions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linagora_P1\n",
      "7235 7235 7235 7235 7235\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "7235 7235 7235 7235\n",
      "7235 7235\n",
      "Linagora_C1\n",
      "1598 1598 1598 1598 1598\n",
      "1598 1598 1598 1598\n",
      "1598 1598\n",
      "Linagora_R1\n",
      "7943 7943 7943 7943 7943\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "7943 7943 7943 7943\n",
      "7943 7943\n",
      "Linagora_A1\n",
      "1809 1809 1809 1809 1809\n",
      "1809 1809 1809 1809\n",
      "ERROR: 1795 à 1804 bon\n",
      "ERROR2\n",
      "1809 1809\n",
      "Linagora_P6\n",
      "9441 9441 9441 9441 9441\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "9441 9441 9441 9441\n",
      "9441 9441\n",
      "Linagora_C3\n",
      "1732 1732 1732 1732 1732\n",
      "1732 1732 1732 1732\n",
      "1732 1732\n",
      "Linagora_P5\n",
      "5720 5720 5720 5720 5720\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "5720 5720 5720 5720\n",
      "5720 5720\n",
      "Linagora_R4\n",
      "9734 9734 9734 9734 9734\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "9734 9734 9734 9734\n",
      "9734 9734\n",
      "Linagora_R3\n",
      "8752 8752 8752 8752 8752\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "8752 8752 8752 8752\n",
      "8752 8752\n",
      "Linagora_C2\n",
      "4457 4457 4457 4457 4457\n",
      "4457 4457 4457 4457\n",
      "4457 4457\n",
      "Linagora_P4\n",
      "13856 13856 13856 13856 13856\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "13856 13856 13856 13856\n",
      "ERROR: 9037 aknowledge 9063 aknowledgement\n",
      "ERROR2\n",
      "13856 13856\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "liste_dataframes=[]\n",
    "name_meeting_list =['Linagora_P1', 'Linagora_C1', 'Linagora_R1', 'Linagora_A1', 'Linagora_P6', 'Linagora_C3', 'Linagora_P5', 'Linagora_R4', 'Linagora_R3', 'Linagora_C2', 'Linagora_P4']\n",
    "\n",
    "for i in range(0,len(name_meeting_list)):\n",
    "    # fichiers\n",
    "    print(name_meeting_list[i])\n",
    "    file_alignments=\"data/alignments/\"+name_meeting_list[i]+\"_align.txt\"\n",
    "    file_spk_change=\"data/speakers/\"+name_meeting_list[i]+\"_spk.txt\"\n",
    "    file_silences=\"data/silences/\"+name_meeting_list[i]+\"_sil.txt\"\n",
    "    file_tony_result=\"data/tony/\"+name_meeting_list[i]+\"_tony.txt.split.tok\"\n",
    "    gold_files=['Linagora_P1', 'Linagora_C1', 'Linagora_R1', 'Linagora_A1']\n",
    "    file_punct=\"data/punctuation/\"+name_meeting_list[i]+\"_punct.txt\"\n",
    "    file_pitchenergy=\"data/audio/\"+name_meeting_list[i]+\"_pitchenergy.txt\"\n",
    "    file_punct_samir=\"data/punctuation_samir/\"+name_meeting_list[i]+\"_samir.txt\"\n",
    "    # calculs\n",
    "    word,beg_word,end_word = alignments_word_extraction(file_alignments)\n",
    "    \n",
    "    real_n_round, real_beg_round, real_end_round, real_rank_round, real_text_round, real_loc=alignments_real_round_extraction(file_alignments)\n",
    "    \n",
    "    beg_sil,end_sil,dur_sil,mid_sil=extract_silences_positions(file_silences)\n",
    "    sil_bef, sil_aft=silences_word_position(word, beg_word, end_word, beg_sil, end_sil, dur_sil, mid_sil)\n",
    "    beg_chg_spk, end_chg_spk = read_change_spk(file_spk_change)\n",
    "    n_round, beg_round, end_round, rank_round, text_round = round_extraction(word, beg_word, end_word, beg_chg_spk, end_chg_spk)\n",
    "    tony=convert_tony_results(file_tony_result, word)\n",
    "    prob_nothing, prob_point, prob_comma, prob_nothing_bef, prob_point_bef, prob_comma_bef = convert_punctuation(file_punct, word)\n",
    "    pitch, pitch_bef, energy, energy_bef = audio_features_extraction(file_pitchenergy, word)\n",
    "    punct, punct_bef= punctuation_samir_extraction(file_punct_samir, word)\n",
    "    \n",
    "    if name_meeting_list[i] in gold_files:\n",
    "        file_gold=\"data/gold/\"+name_meeting_list[i]+\"_gold.txt\"\n",
    "        gold=convert_gold(file_gold)\n",
    "    else:\n",
    "        gold=[0]*len(word)\n",
    "\n",
    "    df = pd.DataFrame({'word': word, 'beg_word': beg_word, 'end_word': end_word,'n_round': n_round,\n",
    "                       'beg_round': beg_round, 'end_round': end_round, 'rank_round' : rank_round,\n",
    "                       'text_round' : text_round, 'sil_bef' : sil_bef, 'sil_aft' : sil_aft, 'tony' : tony,\n",
    "                       'gold': gold, 'prob_nothing' : prob_nothing, 'prob_point': prob_point,\n",
    "                       'prob_comma' : prob_comma, 'prob_nothing_bef' : prob_nothing_bef,\n",
    "                       'prob_point_bef': prob_point_bef, 'prob_comma_bef' : prob_comma_bef,\n",
    "                       'real_rank_round': real_rank_round, 'pitch': pitch, 'energy': energy,\n",
    "                       'pitch_bef': pitch_bef, 'energy_bef': energy_bef, \"punct\": punct, \"punct_bef\":punct_bef})\n",
    "    \n",
    "    \n",
    "    df[\"file\"]=name_meeting_list[i]\n",
    "    liste_dataframes.append(df)\n",
    "                       \n",
    "df_all=pd.concat(liste_dataframes)\n",
    "\n",
    "df_all.head()\n",
    "df_all.to_csv(\"df_all_10022021.csv\")\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>beg_word</th>\n",
       "      <th>end_word</th>\n",
       "      <th>n_round</th>\n",
       "      <th>beg_round</th>\n",
       "      <th>end_round</th>\n",
       "      <th>rank_round</th>\n",
       "      <th>text_round</th>\n",
       "      <th>sil_bef</th>\n",
       "      <th>sil_aft</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_point_bef</th>\n",
       "      <th>prob_comma_bef</th>\n",
       "      <th>real_rank_round</th>\n",
       "      <th>pitch</th>\n",
       "      <th>energy</th>\n",
       "      <th>pitch_bef</th>\n",
       "      <th>energy_bef</th>\n",
       "      <th>punct</th>\n",
       "      <th>punct_bef</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>0</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donc</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>1</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juste</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>2</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comme</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>3</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.286862</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>4</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  beg_word  end_word  n_round  beg_round  end_round  rank_round  \\\n",
       "0     ok      2.00      2.37        0        0.0     10.123           0   \n",
       "1   donc      2.73      3.01        0        0.0     10.123           1   \n",
       "2  juste      3.38      3.67        0        0.0     10.123           2   \n",
       "3  comme      3.92      4.22        0        0.0     10.123           3   \n",
       "4     on      4.23      4.67        0        0.0     10.123           4   \n",
       "\n",
       "                                          text_round  sil_bef  sil_aft  ...  \\\n",
       "0  ok donc juste comme on enregistre euh donc là ...     1.26     0.00  ...   \n",
       "1  ok donc juste comme on enregistre euh donc là ...     0.00     0.24  ...   \n",
       "2  ok donc juste comme on enregistre euh donc là ...     0.24     0.00  ...   \n",
       "3  ok donc juste comme on enregistre euh donc là ...     0.00     0.00  ...   \n",
       "4  ok donc juste comme on enregistre euh donc là ...     0.00     0.12  ...   \n",
       "\n",
       "   prob_point_bef  prob_comma_bef real_rank_round pitch energy pitch_bef  \\\n",
       "0               0               0               0     0      0         0   \n",
       "1               0               0               1     0      0         0   \n",
       "2               0               0               2     U      D         0   \n",
       "3        0.018153        0.286862               3     D      D         U   \n",
       "4        0.000417        0.001607               4     D      U         D   \n",
       "\n",
       "  energy_bef punct  punct_bef         file  \n",
       "0          0     0          0  Linagora_P1  \n",
       "1          0     0          0  Linagora_P1  \n",
       "2          0     0          0  Linagora_P1  \n",
       "3          D     0          0  Linagora_P1  \n",
       "4          D     0          0  Linagora_P1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()\n",
    "#len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.to_csv(\"df_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des fichiers pour samir\n",
    "name_meeting_list =['Linagora_P1', 'Linagora_C1', 'Linagora_R1', 'Linagora_A1', 'Linagora_P6', 'Linagora_C3', 'Linagora_P5', 'Linagora_R4', 'Linagora_R3', 'Linagora_C2', 'Linagora_P4']\n",
    "\n",
    "for i in range(0,len(liste_dataframes)):\n",
    "    df=liste_dataframes[i]\n",
    "    new_file=open(\"samir/\"+name_meeting_list[i]+\"_samir.txt\", \"w\")\n",
    "    liste_mot=[]\n",
    "    for x in df.itertuples():\n",
    "        liste_mot.append(x.word)\n",
    "    \n",
    "    new_file.write(\" \".join(liste_mot))\n",
    "    new_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
