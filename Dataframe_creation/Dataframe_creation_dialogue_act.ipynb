{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Création de la dataframe pour les actes de dialogues dans Snorkel\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1,\"scripts/\")\n",
    "from alignments import *\n",
    "from tony import *\n",
    "from gold import *\n",
    "from silences import *\n",
    "from speaker import *\n",
    "from tony import *\n",
    "from gold import *\n",
    "from punctuation import *\n",
    "from pitchenergy import *\n",
    "from punctuation_samir import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "### 1. Needed Files\n",
    "### 2. List of functions\n",
    "### 3. Data creation for one meeting \n",
    "### 4. Dataframe creation for all meetings \n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Needed Files\n",
    "<br>\n",
    "\n",
    "#### 1. Alignments files\n",
    "<br>\n",
    "For the real use, we will only need the output of the ASR system, which must give the words said and their position in time. For the study, we had to use the output of the software Jtrans, which takes the audio and the .trs file to create the alignments.\n",
    "<br>\n",
    "\n",
    "\n",
    "#### 2. Speaker changes detection files\n",
    "<br>\n",
    "Output files from \"pyannote_SCD_OVL.ipynb\" which takes a wav file as input and gives a file with the limits of speaker changes under the following format hh:mm:ss. We must convert the segments in seconds.\n",
    "<br>\n",
    "\n",
    "#### 3. Segments of silences files\n",
    "\n",
    "Output files from Py WebRTCVad, which look like that: <br>\n",
    "<br>\n",
    "*File : Linagora_A1_0_05_27--end.wav<br>\n",
    "0.09 0.30 0.18 NS<br>\n",
    "0.48 0.63 0.12 NS<br>\n",
    "...*<br>\n",
    "<br>\n",
    "The columns are :\n",
    "Beginning/End/Duration-3s/NS\n",
    "<br>\n",
    "#### 4. Ouptut file of ToNy\n",
    "<br>\n",
    "Output files coming from ToNy. To use ToNy we need files taht can be created with the function data_prep_tony. <br>\n",
    "The output file of ToNy look like this :<br>\n",
    "<br>\n",
    "1\teh\t_\t_\t_\t_\t_\t_\t_\tBeginSeg=Yes<br>\n",
    "2\tben\t_\t_\t_\t_\t_\t_\t_\t_<br>\n",
    "3\tdu\t_\t_\t_\t_\t_\t_\t_\t_<br>\n",
    "4\tcoup\t_\t_\t_\t_\t_\t_\t_\t_<br>\n",
    "5\touais\t_\t_\t_\t_\t_\t_\t_\t_<br>\n",
    "\n",
    "\n",
    "#### 5. Gold (for Dialogue Acts) files\n",
    "<br>\n",
    "For the meetings with gold labels, we need text files with separator | for each dialogue act.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. List of functions\n",
    "<br>\n",
    "\n",
    "### Alignments\n",
    "\n",
    "\n",
    "**alignments_word_extraction(filename_alignments)**\n",
    "> return **word, beg_word, end_word** \n",
    "> respectivement la liste des mots, le début des mots en secondes, la fin des mots en secondes \n",
    "<br>\n",
    "\n",
    "**alignments_real_turn_extraction(filename_alignments)**\n",
    "> return n_turn, beg_turn, end_turn, rank_turn, text_turn, loc\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### Speaker change detection\n",
    "\n",
    "<br>\n",
    "\n",
    "**read_change_spk_detection(filename_change_spk_detection)**\n",
    "> return **beg_chg_spk**, **end_chg_spk**\n",
    "\n",
    "\n",
    "**turn_extraction(word, beg_word, end_word, beg_chg_spk ,end_chg_spk)**\n",
    "> return **n_turn**, **beg_turn**, **end_turn**, **rank_turn**, **text_turn**\n",
    "\n",
    "<br>\n",
    "\n",
    "### Silences\n",
    "\n",
    "<br>\n",
    "\n",
    "**extract_silences_positions(filename_silences)**\n",
    "> return **beg_sil**, **end_sil**, **dur_sil**, **mid_sil**\n",
    "\n",
    "\n",
    "**silences_word_position(word, beg_word, end_word, beg_sil, end_sil, dur_sil, mid_sil)**\n",
    "> return **sil_bef**, **sil_aft**\n",
    "\n",
    "<br>\n",
    "\n",
    "### ToNy \n",
    "\n",
    "<br>\n",
    "\n",
    "**data_prep_tony(name, word, rank_turn, text_turn)**\n",
    "> create file for ToNy\n",
    "\n",
    "\n",
    "**convert_tony_results(filename_tony_result)**\n",
    "> return **tony**\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### Gold\n",
    "\n",
    "<br>\n",
    "\n",
    "**convert_gold(filename_gold)**\n",
    "> return **gold**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Punctuation\n",
    "\n",
    "<br>\n",
    "\n",
    "**convert_punctuation(filename_punct)**\n",
    "> return **prob_nothing**, **prob_period**, **prob_comma**, **prob_nothing_bef**, **prob_period_bef**, **prob_comma_bef**\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**punctuation_samir_extraction(file_punctuation, word)**\n",
    "> return **punct**, **punct_bef**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data creation for one meeting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emplacement des fichiers : \n",
    "\n",
    "name_meeting=\"Linagora_R1\"\n",
    "file_alignments=\"data/alignments/Linagora_R1_align.txt\"\n",
    "file_spk_change=\"data/speakers/Linagora_R1_spk.txt\"\n",
    "file_silences=\"data/silences/Linagora_R1_sil.txt\"\n",
    "file_tony_result=\"data/tony/Linagora_R1_tony.txt.split.tok\"\n",
    "file_gold=\"data/gold/Linagora_R1_gold.txt\"\n",
    "file_punct=\"data/punctuation/Linagora_R1_punct.txt\"\n",
    "file_punct_samir=\"data/punctuation_samir/Linagora_R1_samir.txt\"\n",
    "file_pitchenergy=\"data/audio/Linagora_R1_pitchenergy.txt\"\n",
    "\n",
    "    \n",
    "work_directory=\"path\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alignements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943 7943 7943\n"
     ]
    }
   ],
   "source": [
    "word,beg_word,end_word = alignments_word_extraction(file_alignments)\n",
    "print(len(word), len(beg_word), len(end_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943 7943 7943 7943 7943\n"
     ]
    }
   ],
   "source": [
    "real_n_turn, real_beg_turn, real_end_turn, real_rank_turn, real_text_turn, real_loc=alignments_real_turn_extraction(file_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Silences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943 7943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "beg_sil,end_sil,dur_sil,mid_sil=extract_silences_positions(file_silences)\n",
    "sil_bef, sil_aft=silences_word_position(word, beg_word, end_word, beg_sil, end_sil, dur_sil, mid_sil)\n",
    "\n",
    "print(len(sil_bef), len(sil_aft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Speaker change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 119\n",
      "7943 7943 7943 7943 7943 119 119\n"
     ]
    }
   ],
   "source": [
    "beg_chg_spk, end_chg_spk = read_change_spk(file_spk_change)\n",
    "print(len(beg_chg_spk), len(end_chg_spk))\n",
    "n_turn, beg_turn, end_turn, rank_turn, text_turn = turn_extraction(word, beg_word, end_word, beg_chg_spk, end_chg_spk)\n",
    "\n",
    "print(len(n_turn), len(beg_turn), len(end_turn), len(rank_turn), len(text_turn), len(beg_chg_spk), len(end_chg_spk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ToNy Begin Of Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_prep_tony(name_meeting, word, rank_turn, text_turn)\n",
    "tony=convert_tony_results(file_tony_result, word)\n",
    "\n",
    "print(len(tony))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gold BOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7943\n"
     ]
    }
   ],
   "source": [
    "if file_gold!=\"\":\n",
    "    gold=convert_gold(file_gold)\n",
    "    print(len(gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ponctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "7943\n",
      "7943 7943\n"
     ]
    }
   ],
   "source": [
    "prob_nothing, prob_period, prob_comma, prob_nothing_bef, prob_period_bef, prob_comma_bef = convert_punctuation(file_punct, word)\n",
    "print(len(prob_nothing))\n",
    "\n",
    "\n",
    "#ponctuation samir\n",
    "\n",
    "punct_bef, punct=punctuation_samir_extraction(file_punct_samir, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "7943 7943 7943 7943\n"
     ]
    }
   ],
   "source": [
    "pitch, pitch_bef, energy, energy_bef = audio_features_extraction(file_pitchenergy, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 137 67 7697\n",
      "precision= 0.3853211009174312 rappel= 0.2346368715083799 fscore= 0.2916666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vp=0\n",
    "fn=0\n",
    "fp=0\n",
    "vn=0\n",
    "\n",
    "\n",
    "for i in range(0,len(rank_turn)):\n",
    "    if rank_turn[i]==0 and real_rank_turn[i]==0:\n",
    "        vp+=1\n",
    "    elif rank_turn[i]!=0 and real_rank_turn[i]==0:\n",
    "        fn+=1\n",
    "    elif rank_turn[i]==0 and real_rank_turn[i]!=0:\n",
    "        fp+=1\n",
    "    else:\n",
    "        vn+=1\n",
    "\n",
    "print(vp, fn, fp, vn)\n",
    "p=vp/(vp+fp)\n",
    "r=vp/(vp+fn)\n",
    "fscore=2*p*r/(p+r)\n",
    "\n",
    "print(\"precision=\", p, \"rappel=\", r, \"fscore=\", fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_dev = pd.DataFrame({'word': word, 'beg_word': beg_word, 'end_word': end_word,'n_turn': n_turn,\n",
    "                       'beg_turn': beg_turn, 'end_turn': end_turn, 'rank_turn' : rank_turn,\n",
    "                       'text_turn' : text_turn, 'sil_bef' : sil_bef, 'sil_aft' : sil_aft, 'tony' : tony,\n",
    "                       'gold': gold, 'prob_nothing' : prob_nothing, 'prob_period': prob_period,\n",
    "                       'prob_comma' : prob_comma, 'prob_nothing_bef' : prob_nothing_bef,\n",
    "                       'prob_period_bef': prob_period_bef, 'prob_comma_bef' : prob_comma_bef,\n",
    "                       'real_rank_turn': real_rank_turn, 'pitch': pitch, 'energy': energy,\n",
    "                       'pitch_bef': pitch_bef, 'energy_bef': energy_bef})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bonjou\n"
     ]
    }
   ],
   "source": [
    "#df_dev=\n",
    "file=open(\"spk_change_comparison_R1.txt\", \"w\")\n",
    "\n",
    "\n",
    "i=0\n",
    "liste_texte=[]\n",
    "\n",
    "for x in df_dev.itertuples():\n",
    "    mot=x.word\n",
    "    if x.real_rank_turn==0 :\n",
    "        if float(x.prob_period_bef)<0.5 and i>0 and float(x.prob_comma_bef)<0.5:\n",
    "            liste_texte.append(\".\")\n",
    "        liste_texte.append(\"\\n\"+\"\\n\"+\"---Real turn---\"+\"\\n\"+\"\\n\")\n",
    "        \n",
    "\n",
    "    if x.rank_turn==0:\n",
    "        liste_texte.append(\"|D_SPK|\")\n",
    "    \n",
    "    #if label[i]==1:\n",
    "        #liste_texte.append(\"|D_BOS|\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    if float(x.prob_period_bef)>0.5 or x.real_rank_turn==0:\n",
    "        mot=str(mot).capitalize()\n",
    "    \n",
    "    if float(x.prob_period)>0.5:\n",
    "        mot=mot+\".\"\n",
    "\n",
    "    if float(x.prob_comma)>0.5:\n",
    "        mot=mot+\",\"\n",
    "\n",
    "    liste_texte.append(mot)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    i+=1\n",
    "    if i==len(df_dev):\n",
    "        liste_texte.append(\".\")\n",
    "\n",
    "file.write(\" \".join(liste_texte))\n",
    "print(\"bonjou\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"real_turns.txt\", \"w\")\n",
    "\n",
    "for i in range(0,len(real_rank_turn)):\n",
    "    if real_rank_turn[i]==0:\n",
    "        file.write(str(turn(real_beg_turn[i],3))+\" \"+str(turn(real_end_turn[i],3))+\" \"+real_loc[i]+\"\\n\")\n",
    "\n",
    "file.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataframe creation for all meetings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linagora_P1\n",
      "7235 7235 7235 7235 7235\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "7235 7235 7235 7235\n",
      "7235 7235\n",
      "Linagora_C1\n",
      "1598 1598 1598 1598 1598\n",
      "1598 1598 1598 1598\n",
      "1598 1598\n",
      "Linagora_R1\n",
      "7943 7943 7943 7943 7943\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "7943 7943 7943 7943\n",
      "7943 7943\n",
      "Linagora_A1\n",
      "1809 1809 1809 1809 1809\n",
      "1809 1809 1809 1809\n",
      "ERROR: 1795 à 1804 bon\n",
      "ERROR2\n",
      "1809 1809\n",
      "Linagora_P6\n",
      "9441 9441 9441 9441 9441\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "9441 9441 9441 9441\n",
      "9441 9441\n",
      "Linagora_C3\n",
      "1732 1732 1732 1732 1732\n",
      "1732 1732 1732 1732\n",
      "1732 1732\n",
      "Linagora_P5\n",
      "5720 5720 5720 5720 5720\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "5720 5720 5720 5720\n",
      "5720 5720\n",
      "Linagora_R4\n",
      "9734 9734 9734 9734 9734\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "9734 9734 9734 9734\n",
      "9734 9734\n",
      "Linagora_R3\n",
      "8752 8752 8752 8752 8752\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "8752 8752 8752 8752\n",
      "8752 8752\n",
      "Linagora_C2\n",
      "4457 4457 4457 4457 4457\n",
      "4457 4457 4457 4457\n",
      "4457 4457\n",
      "Linagora_P4\n",
      "13856 13856 13856 13856 13856\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "exception_a\n",
      "13856 13856 13856 13856\n",
      "ERROR: 9037 aknowledge 9063 aknowledgement\n",
      "ERROR2\n",
      "13856 13856\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "liste_dataframes=[]\n",
    "name_meeting_list =['Linagora_P1', 'Linagora_C1', 'Linagora_R1', 'Linagora_A1', 'Linagora_P6', 'Linagora_C3', 'Linagora_P5', 'Linagora_R4', 'Linagora_R3', 'Linagora_C2', 'Linagora_P4']\n",
    "\n",
    "for i in range(0,len(name_meeting_list)):\n",
    "    # fichiers\n",
    "    print(name_meeting_list[i])\n",
    "    file_alignments=\"data/alignments/\"+name_meeting_list[i]+\"_align.txt\"\n",
    "    file_spk_change=\"data/speakers/\"+name_meeting_list[i]+\"_spk.txt\"\n",
    "    file_silences=\"data/silences/\"+name_meeting_list[i]+\"_sil.txt\"\n",
    "    file_tony_result=\"data/tony/\"+name_meeting_list[i]+\"_tony.txt.split.tok\"\n",
    "    gold_files=['Linagora_P1', 'Linagora_C1', 'Linagora_R1', 'Linagora_A1']\n",
    "    file_punct=\"data/punctuation/\"+name_meeting_list[i]+\"_punct.txt\"\n",
    "    file_pitchenergy=\"data/audio/\"+name_meeting_list[i]+\"_pitchenergy.txt\"\n",
    "    file_punct_samir=\"data/punctuation_samir/\"+name_meeting_list[i]+\"_samir.txt\"\n",
    "    # calculs\n",
    "    word,beg_word,end_word = alignments_word_extraction(file_alignments)\n",
    "    \n",
    "    real_n_turn, real_beg_turn, real_end_turn, real_rank_turn, real_text_turn, real_loc=alignments_real_turn_extraction(file_alignments)\n",
    "    \n",
    "    beg_sil,end_sil,dur_sil,mid_sil=extract_silences_positions(file_silences)\n",
    "    sil_bef, sil_aft=silences_word_position(word, beg_word, end_word, beg_sil, end_sil, dur_sil, mid_sil)\n",
    "    beg_chg_spk, end_chg_spk = read_change_spk(file_spk_change)\n",
    "    n_turn, beg_turn, end_turn, rank_turn, text_turn = turn_extraction(word, beg_word, end_word, beg_chg_spk, end_chg_spk)\n",
    "    tony=convert_tony_results(file_tony_result, word)\n",
    "    prob_nothing, prob_period, prob_comma, prob_nothing_bef, prob_period_bef, prob_comma_bef = convert_punctuation(file_punct, word)\n",
    "    pitch, pitch_bef, energy, energy_bef = audio_features_extraction(file_pitchenergy, word)\n",
    "    punct, punct_bef= punctuation_samir_extraction(file_punct_samir, word)\n",
    "    \n",
    "    if name_meeting_list[i] in gold_files:\n",
    "        file_gold=\"data/gold/\"+name_meeting_list[i]+\"_gold.txt\"\n",
    "        gold=convert_gold(file_gold)\n",
    "    else:\n",
    "        gold=[0]*len(word)\n",
    "\n",
    "    df = pd.DataFrame({'word': word, 'beg_word': beg_word, 'end_word': end_word,'n_turn': n_turn,\n",
    "                       'beg_turn': beg_turn, 'end_turn': end_turn, 'rank_turn' : rank_turn,\n",
    "                       'text_turn' : text_turn, 'sil_bef' : sil_bef, 'sil_aft' : sil_aft, 'tony' : tony,\n",
    "                       'gold': gold, 'prob_nothing' : prob_nothing, 'prob_period': prob_period,\n",
    "                       'prob_comma' : prob_comma, 'prob_nothing_bef' : prob_nothing_bef,\n",
    "                       'prob_period_bef': prob_period_bef, 'prob_comma_bef' : prob_comma_bef,\n",
    "                       'real_rank_turn': real_rank_turn, 'pitch': pitch, 'energy': energy,\n",
    "                       'pitch_bef': pitch_bef, 'energy_bef': energy_bef, \"punct\": punct, \"punct_bef\":punct_bef})\n",
    "    \n",
    "    \n",
    "    df[\"file\"]=name_meeting_list[i]\n",
    "    liste_dataframes.append(df)\n",
    "                       \n",
    "df_all=pd.concat(liste_dataframes)\n",
    "\n",
    "df_all.head()\n",
    "df_all.to_csv(\"df_all_10022021.csv\")\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>beg_word</th>\n",
       "      <th>end_word</th>\n",
       "      <th>n_round</th>\n",
       "      <th>beg_round</th>\n",
       "      <th>end_round</th>\n",
       "      <th>rank_round</th>\n",
       "      <th>text_round</th>\n",
       "      <th>sil_bef</th>\n",
       "      <th>sil_aft</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_point_bef</th>\n",
       "      <th>prob_comma_bef</th>\n",
       "      <th>real_rank_round</th>\n",
       "      <th>pitch</th>\n",
       "      <th>energy</th>\n",
       "      <th>pitch_bef</th>\n",
       "      <th>energy_bef</th>\n",
       "      <th>punct</th>\n",
       "      <th>punct_bef</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>0</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donc</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>1</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juste</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>2</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comme</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>3</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.286862</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.123</td>\n",
       "      <td>4</td>\n",
       "      <td>ok donc juste comme on enregistre euh donc là ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>U</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Linagora_P1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  beg_word  end_word  n_round  beg_round  end_round  rank_round  \\\n",
       "0     ok      2.00      2.37        0        0.0     10.123           0   \n",
       "1   donc      2.73      3.01        0        0.0     10.123           1   \n",
       "2  juste      3.38      3.67        0        0.0     10.123           2   \n",
       "3  comme      3.92      4.22        0        0.0     10.123           3   \n",
       "4     on      4.23      4.67        0        0.0     10.123           4   \n",
       "\n",
       "                                          text_round  sil_bef  sil_aft  ...  \\\n",
       "0  ok donc juste comme on enregistre euh donc là ...     1.26     0.00  ...   \n",
       "1  ok donc juste comme on enregistre euh donc là ...     0.00     0.24  ...   \n",
       "2  ok donc juste comme on enregistre euh donc là ...     0.24     0.00  ...   \n",
       "3  ok donc juste comme on enregistre euh donc là ...     0.00     0.00  ...   \n",
       "4  ok donc juste comme on enregistre euh donc là ...     0.00     0.12  ...   \n",
       "\n",
       "   prob_point_bef  prob_comma_bef real_rank_round pitch energy pitch_bef  \\\n",
       "0               0               0               0     0      0         0   \n",
       "1               0               0               1     0      0         0   \n",
       "2               0               0               2     U      D         0   \n",
       "3        0.018153        0.286862               3     D      D         U   \n",
       "4        0.000417        0.001607               4     D      U         D   \n",
       "\n",
       "  energy_bef punct  punct_bef         file  \n",
       "0          0     0          0  Linagora_P1  \n",
       "1          0     0          0  Linagora_P1  \n",
       "2          0     0          0  Linagora_P1  \n",
       "3          D     0          0  Linagora_P1  \n",
       "4          D     0          0  Linagora_P1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()\n",
    "#len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.to_csv(\"df_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des fichiers pour samir\n",
    "name_meeting_list =['Linagora_P1', 'Linagora_C1', 'Linagora_R1', 'Linagora_A1', 'Linagora_P6', 'Linagora_C3', 'Linagora_P5', 'Linagora_R4', 'Linagora_R3', 'Linagora_C2', 'Linagora_P4']\n",
    "\n",
    "for i in range(0,len(liste_dataframes)):\n",
    "    df=liste_dataframes[i]\n",
    "    new_file=open(\"samir/\"+name_meeting_list[i]+\"_samir.txt\", \"w\")\n",
    "    liste_mot=[]\n",
    "    for x in df.itertuples():\n",
    "        liste_mot.append(x.word)\n",
    "    \n",
    "    new_file.write(\" \".join(liste_mot))\n",
    "    new_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
